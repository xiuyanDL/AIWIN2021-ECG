{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vO9xs8Ql1Ue_"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from gensim.models import word2vec\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import random\n",
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "# 设置随机数种子\n",
    "setup_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EhHAlvgX2EqW"
   },
   "outputs": [],
   "source": [
    "path = 'drive/MyDrive/心电图/'\n",
    "df = pd.read_csv(path+'trainreference.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "I8VPF5eR3BNf"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "setup_seed(2021)\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self, df, idx=None, if_train=True):\n",
    "        self.if_train = if_train\n",
    "        if self.if_train:\n",
    "            self.paths = df.loc[idx, 'name'].reset_index(drop=True)\n",
    "            self.labels = df.loc[idx, 'tag'].reset_index(drop=True)\n",
    "        else:\n",
    "            self.paths = df['name'].reset_index(drop=True)\n",
    "            self.labels = df['tag'].reset_index(drop=True)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.if_train:\n",
    "            sample = sio.loadmat(path+'train/'+self.paths[index])['ecgdata']\n",
    "        else:\n",
    "            sample = sio.loadmat(path+'val/'+self.paths[index])['ecgdata']\n",
    "        return sample, self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MXtf9sbs3o5d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class SeqNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SeqNet, self).__init__()\n",
    "        # input \n",
    "        self.conv1 = nn.Conv1d(12, 10, 50)\n",
    "        self.conv2 = nn.Conv1d(12, 10, 200)\n",
    "        self.conv3 = nn.Conv1d(12, 10, 500)\n",
    "        self.conv4 = nn.Conv1d(12, 10, 1000)\n",
    "        self.pooling = nn.MaxPool2d((1, 200))\n",
    "        self.fc1 = nn.Linear(900, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        out1 = self.pooling(F.relu(self.conv1(x)))\n",
    "        out2 = self.pooling(F.relu(self.conv2(x)))\n",
    "        out3 = self.pooling(F.relu(self.conv3(x)))\n",
    "        out4 = self.pooling(F.relu(self.conv4(x)))\n",
    "\n",
    "        out = torch.cat([out1, out2, out3, out4], 2)\n",
    "        out = out.view(batch_size, -1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        # out = F.dropout(out, p=0.2)\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NM5cBxxg3r4m"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "max_epoch = 20\n",
    "model_save_dir = path+'model/'\n",
    "def train_model(model, criterion, optimizer, lr_scheduler=None):\n",
    "    total_iters=len(trainloader)\n",
    "    print('--------------total_iters:{}'.format(total_iters))\n",
    "    since = time.time()\n",
    "    best_loss = 1e7\n",
    "    best_epoch = 0\n",
    "    best_f1 = 0\n",
    "    #\n",
    "    iters = len(trainloader)\n",
    "    for epoch in range(1,max_epoch+1):\n",
    "        model.train(True)\n",
    "        begin_time=time.time()\n",
    "        # print('learning rate:{}'.format(optimizer.param_groups[-1]['lr']))\n",
    "        print('Fold{} Epoch {}/{}'.format(fold+1,epoch, max_epoch))\n",
    "        running_corrects_linear = 0\n",
    "        count=0\n",
    "        train_loss = []\n",
    "        for i, (inputs, labels) in (enumerate(trainloader)):\n",
    "            # print(inputs)\n",
    "            count+=1\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.float().to(device)\n",
    "\n",
    "            out_linear = model(inputs).to(device)\n",
    "            loss = criterion(out_linear, labels.unsqueeze(1))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # 更新cosine学习率\n",
    "            if lr_scheduler!=None:\n",
    "                lr_scheduler.step(epoch + count / iters)\n",
    "            if print_interval>0 and (i % print_interval == 0 or out_linear.size()[0] < train_batch_size):\n",
    "                spend_time = time.time() - begin_time\n",
    "                print(\n",
    "                    ' Fold:{} Epoch:{}({}/{}) loss:{:.3f} lr:{:.7f} epoch_Time:{}min:'.format(\n",
    "                        fold+1,epoch, count, total_iters,\n",
    "                        loss.item(), optimizer.param_groups[-1]['lr'],\n",
    "                        spend_time / count * total_iters // 60 - spend_time // 60))\n",
    "            #\n",
    "            train_loss.append(loss.item())\n",
    "        #lr_scheduler.step()\n",
    "        val_f1, val_loss= val_model(model, criterion)\n",
    "        print('valf1: {:.4f}  valLogLoss: {:.4f}'.format(val_f1, val_loss))\n",
    "        model_out_path = model_save_dir+\"/\"+'fold_'+str(fold+1)+'_'+str(epoch) + '.pth'\n",
    "        best_model_out_path = model_save_dir+\"/\"+'fold_'+str(fold+1)+'_best'+'.pth'\n",
    "        #save the best model\n",
    "        if val_f1 >= best_f1:\n",
    "            best_loss = val_loss\n",
    "            best_f1 = val_f1\n",
    "            best_epoch=epoch\n",
    "            torch.save(model.state_dict(), best_model_out_path)\n",
    "            print(\"save best epoch: {} best f1: {:.5f} best logloss: {:.5f}\".format(best_epoch,val_f1,val_loss))\n",
    "  \n",
    "    print('Fold{} Best f1: {:.3f} Best logloss: {:.3f} Best epoch:{}'.format(fold+1,best_f1, best_loss,best_epoch))\n",
    "    time_elapsed = time.time() - since\n",
    "    return best_loss, best_f1\n",
    "\n",
    "@torch.no_grad()\n",
    "def val_model(model, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    cont = 0\n",
    "    outPre = []\n",
    "    outLabel = []\n",
    "    pres_list=[]\n",
    "    labels_list=[]\n",
    "    for data in val_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        outputs = model(inputs)\n",
    "        pres_list+=outputs.sigmoid().detach().cpu().numpy().tolist()\n",
    "        labels_list+=labels.detach().cpu().numpy().tolist()\n",
    "\n",
    "    preds = np.array(pres_list)\n",
    "    labels = np.array(labels_list)\n",
    "    val_f1 = metrics.f1_score(labels, list(map(lambda x: 1 if x > 0.5 else 0, preds)))\n",
    "    log_loss = metrics.log_loss(labels, preds)#\n",
    "    return val_f1, log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kLZ9XWWl3ybD",
    "outputId": "b2db66d2-9c28-422e-c102-08cf9d291798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "--------------total_iters:40\n",
      "Fold1 Epoch 1/20\n",
      "valf1: 0.5882  valLogLoss: 0.6690\n",
      "save best epoch: 1 best f1: 0.58824 best logloss: 0.66902\n",
      "Fold1 Epoch 2/20\n",
      "valf1: 0.7696  valLogLoss: 0.6188\n",
      "save best epoch: 2 best f1: 0.76963 best logloss: 0.61883\n",
      "Fold1 Epoch 3/20\n",
      "valf1: 0.7797  valLogLoss: 0.5340\n",
      "save best epoch: 3 best f1: 0.77966 best logloss: 0.53395\n",
      "Fold1 Epoch 4/20\n",
      "valf1: 0.7781  valLogLoss: 0.4845\n",
      "Fold1 Epoch 5/20\n",
      "valf1: 0.7988  valLogLoss: 0.4509\n",
      "save best epoch: 5 best f1: 0.79878 best logloss: 0.45091\n",
      "Fold1 Epoch 6/20\n",
      "valf1: 0.8082  valLogLoss: 0.4231\n",
      "save best epoch: 6 best f1: 0.80822 best logloss: 0.42306\n",
      "Fold1 Epoch 7/20\n",
      "valf1: 0.8072  valLogLoss: 0.4224\n",
      "Fold1 Epoch 8/20\n",
      "valf1: 0.8143  valLogLoss: 0.3949\n",
      "save best epoch: 8 best f1: 0.81433 best logloss: 0.39485\n",
      "Fold1 Epoch 9/20\n",
      "valf1: 0.7987  valLogLoss: 0.4063\n",
      "Fold1 Epoch 10/20\n",
      "valf1: 0.8173  valLogLoss: 0.3972\n",
      "save best epoch: 10 best f1: 0.81734 best logloss: 0.39722\n",
      "Fold1 Epoch 11/20\n",
      "valf1: 0.8194  valLogLoss: 0.3885\n",
      "save best epoch: 11 best f1: 0.81935 best logloss: 0.38853\n",
      "Fold1 Epoch 12/20\n",
      "valf1: 0.8182  valLogLoss: 0.3860\n",
      "Fold1 Epoch 13/20\n",
      "valf1: 0.8153  valLogLoss: 0.3883\n",
      "Fold1 Epoch 14/20\n",
      "valf1: 0.8187  valLogLoss: 0.3844\n",
      "Fold1 Epoch 15/20\n",
      "valf1: 0.8148  valLogLoss: 0.3872\n",
      "Fold1 Epoch 16/20\n",
      "valf1: 0.8150  valLogLoss: 0.3823\n",
      "Fold1 Epoch 17/20\n",
      "valf1: 0.8150  valLogLoss: 0.3818\n",
      "Fold1 Epoch 18/20\n",
      "valf1: 0.8150  valLogLoss: 0.3815\n",
      "Fold1 Epoch 19/20\n",
      "valf1: 0.8150  valLogLoss: 0.3817\n",
      "Fold1 Epoch 20/20\n",
      "valf1: 0.8113  valLogLoss: 0.3817\n",
      "Fold1 Best f1: 0.819 Best logloss: 0.389 Best epoch:11\n",
      "--------------total_iters:40\n",
      "Fold2 Epoch 1/20\n",
      "valf1: 0.6824  valLogLoss: 0.6826\n",
      "save best epoch: 1 best f1: 0.68241 best logloss: 0.68261\n",
      "Fold2 Epoch 2/20\n",
      "valf1: 0.7016  valLogLoss: 0.6322\n",
      "save best epoch: 2 best f1: 0.70157 best logloss: 0.63222\n",
      "Fold2 Epoch 3/20\n",
      "valf1: 0.7541  valLogLoss: 0.5596\n",
      "save best epoch: 3 best f1: 0.75410 best logloss: 0.55959\n",
      "Fold2 Epoch 4/20\n",
      "valf1: 0.7582  valLogLoss: 0.5534\n",
      "save best epoch: 4 best f1: 0.75821 best logloss: 0.55336\n",
      "Fold2 Epoch 5/20\n",
      "valf1: 0.7331  valLogLoss: 0.5242\n",
      "Fold2 Epoch 6/20\n",
      "valf1: 0.7826  valLogLoss: 0.5460\n",
      "save best epoch: 6 best f1: 0.78261 best logloss: 0.54604\n",
      "Fold2 Epoch 7/20\n",
      "valf1: 0.7947  valLogLoss: 0.5162\n",
      "save best epoch: 7 best f1: 0.79470 best logloss: 0.51616\n",
      "Fold2 Epoch 8/20\n",
      "valf1: 0.7864  valLogLoss: 0.5110\n",
      "Fold2 Epoch 9/20\n",
      "valf1: 0.7761  valLogLoss: 0.5519\n",
      "Fold2 Epoch 10/20\n",
      "valf1: 0.7987  valLogLoss: 0.4956\n",
      "save best epoch: 10 best f1: 0.79872 best logloss: 0.49560\n",
      "Fold2 Epoch 11/20\n",
      "valf1: 0.7947  valLogLoss: 0.5104\n",
      "Fold2 Epoch 12/20\n",
      "valf1: 0.8173  valLogLoss: 0.5147\n",
      "save best epoch: 12 best f1: 0.81734 best logloss: 0.51473\n",
      "Fold2 Epoch 13/20\n",
      "valf1: 0.8065  valLogLoss: 0.5068\n",
      "Fold2 Epoch 14/20\n",
      "valf1: 0.8100  valLogLoss: 0.5123\n",
      "Fold2 Epoch 15/20\n",
      "valf1: 0.8117  valLogLoss: 0.5056\n",
      "Fold2 Epoch 16/20\n",
      "valf1: 0.8202  valLogLoss: 0.5048\n",
      "save best epoch: 16 best f1: 0.82019 best logloss: 0.50478\n",
      "Fold2 Epoch 17/20\n",
      "valf1: 0.8254  valLogLoss: 0.5045\n",
      "save best epoch: 17 best f1: 0.82540 best logloss: 0.50449\n",
      "Fold2 Epoch 18/20\n",
      "valf1: 0.8254  valLogLoss: 0.5047\n",
      "save best epoch: 18 best f1: 0.82540 best logloss: 0.50472\n",
      "Fold2 Epoch 19/20\n",
      "valf1: 0.8254  valLogLoss: 0.5048\n",
      "save best epoch: 19 best f1: 0.82540 best logloss: 0.50477\n",
      "Fold2 Epoch 20/20\n",
      "valf1: 0.8254  valLogLoss: 0.5047\n",
      "save best epoch: 20 best f1: 0.82540 best logloss: 0.50472\n",
      "Fold2 Best f1: 0.825 Best logloss: 0.505 Best epoch:20\n",
      "--------------total_iters:40\n",
      "Fold3 Epoch 1/20\n",
      "valf1: 0.6933  valLogLoss: 0.6762\n",
      "save best epoch: 1 best f1: 0.69333 best logloss: 0.67623\n",
      "Fold3 Epoch 2/20\n",
      "valf1: 0.6250  valLogLoss: 0.6375\n",
      "Fold3 Epoch 3/20\n",
      "valf1: 0.7333  valLogLoss: 0.5735\n",
      "save best epoch: 3 best f1: 0.73333 best logloss: 0.57347\n",
      "Fold3 Epoch 4/20\n",
      "valf1: 0.7834  valLogLoss: 0.5258\n",
      "save best epoch: 4 best f1: 0.78338 best logloss: 0.52583\n",
      "Fold3 Epoch 5/20\n",
      "valf1: 0.7466  valLogLoss: 0.4932\n",
      "Fold3 Epoch 6/20\n",
      "valf1: 0.7846  valLogLoss: 0.4689\n",
      "save best epoch: 6 best f1: 0.78457 best logloss: 0.46893\n",
      "Fold3 Epoch 7/20\n",
      "valf1: 0.7826  valLogLoss: 0.4693\n",
      "Fold3 Epoch 8/20\n",
      "valf1: 0.7915  valLogLoss: 0.4721\n",
      "save best epoch: 8 best f1: 0.79154 best logloss: 0.47205\n",
      "Fold3 Epoch 9/20\n",
      "valf1: 0.7864  valLogLoss: 0.4580\n",
      "Fold3 Epoch 10/20\n",
      "valf1: 0.7898  valLogLoss: 0.4481\n",
      "Fold3 Epoch 11/20\n",
      "valf1: 0.7914  valLogLoss: 0.4532\n",
      "Fold3 Epoch 12/20\n",
      "valf1: 0.7862  valLogLoss: 0.4479\n",
      "Fold3 Epoch 13/20\n",
      "valf1: 0.8037  valLogLoss: 0.4483\n",
      "save best epoch: 13 best f1: 0.80368 best logloss: 0.44825\n",
      "Fold3 Epoch 14/20\n",
      "valf1: 0.7988  valLogLoss: 0.4481\n",
      "Fold3 Epoch 15/20\n",
      "valf1: 0.7988  valLogLoss: 0.4408\n",
      "Fold3 Epoch 16/20\n",
      "valf1: 0.8037  valLogLoss: 0.4435\n",
      "save best epoch: 16 best f1: 0.80368 best logloss: 0.44353\n",
      "Fold3 Epoch 17/20\n",
      "valf1: 0.8037  valLogLoss: 0.4454\n",
      "save best epoch: 17 best f1: 0.80368 best logloss: 0.44539\n",
      "Fold3 Epoch 18/20\n",
      "valf1: 0.8037  valLogLoss: 0.4462\n",
      "save best epoch: 18 best f1: 0.80368 best logloss: 0.44618\n",
      "Fold3 Epoch 19/20\n",
      "valf1: 0.8037  valLogLoss: 0.4460\n",
      "save best epoch: 19 best f1: 0.80368 best logloss: 0.44600\n",
      "Fold3 Epoch 20/20\n",
      "valf1: 0.8037  valLogLoss: 0.4461\n",
      "save best epoch: 20 best f1: 0.80368 best logloss: 0.44609\n",
      "Fold3 Best f1: 0.804 Best logloss: 0.446 Best epoch:20\n",
      "--------------total_iters:40\n",
      "Fold4 Epoch 1/20\n",
      "valf1: 0.6785  valLogLoss: 0.6831\n",
      "save best epoch: 1 best f1: 0.67849 best logloss: 0.68311\n",
      "Fold4 Epoch 2/20\n",
      "valf1: 0.6364  valLogLoss: 0.6521\n",
      "Fold4 Epoch 3/20\n",
      "valf1: 0.7892  valLogLoss: 0.5594\n",
      "save best epoch: 3 best f1: 0.78916 best logloss: 0.55940\n",
      "Fold4 Epoch 4/20\n",
      "valf1: 0.8025  valLogLoss: 0.5063\n",
      "save best epoch: 4 best f1: 0.80255 best logloss: 0.50630\n",
      "Fold4 Epoch 5/20\n",
      "valf1: 0.7688  valLogLoss: 0.5307\n",
      "Fold4 Epoch 6/20\n",
      "valf1: 0.8404  valLogLoss: 0.4669\n",
      "save best epoch: 6 best f1: 0.84039 best logloss: 0.46689\n",
      "Fold4 Epoch 7/20\n",
      "valf1: 0.8339  valLogLoss: 0.4436\n",
      "Fold4 Epoch 8/20\n",
      "valf1: 0.8301  valLogLoss: 0.4398\n",
      "Fold4 Epoch 9/20\n",
      "valf1: 0.8294  valLogLoss: 0.4361\n",
      "Fold4 Epoch 10/20\n",
      "valf1: 0.8246  valLogLoss: 0.4370\n",
      "Fold4 Epoch 11/20\n",
      "valf1: 0.8285  valLogLoss: 0.4265\n",
      "Fold4 Epoch 12/20\n",
      "valf1: 0.8278  valLogLoss: 0.4236\n",
      "Fold4 Epoch 13/20\n",
      "valf1: 0.8265  valLogLoss: 0.4249\n",
      "Fold4 Epoch 14/20\n",
      "valf1: 0.8344  valLogLoss: 0.4227\n",
      "Fold4 Epoch 15/20\n",
      "valf1: 0.8344  valLogLoss: 0.4201\n",
      "Fold4 Epoch 16/20\n",
      "valf1: 0.8383  valLogLoss: 0.4179\n",
      "Fold4 Epoch 17/20\n",
      "valf1: 0.8383  valLogLoss: 0.4179\n",
      "Fold4 Epoch 18/20\n",
      "valf1: 0.8383  valLogLoss: 0.4185\n",
      "Fold4 Epoch 19/20\n",
      "valf1: 0.8383  valLogLoss: 0.4185\n",
      "Fold4 Epoch 20/20\n",
      "valf1: 0.8383  valLogLoss: 0.4185\n",
      "Fold4 Best f1: 0.840 Best logloss: 0.467 Best epoch:6\n",
      "--------------total_iters:40\n",
      "Fold5 Epoch 1/20\n",
      "valf1: 0.6705  valLogLoss: 0.6767\n",
      "save best epoch: 1 best f1: 0.67049 best logloss: 0.67667\n",
      "Fold5 Epoch 2/20\n",
      "valf1: 0.6420  valLogLoss: 0.6220\n",
      "Fold5 Epoch 3/20\n",
      "valf1: 0.7805  valLogLoss: 0.5506\n",
      "save best epoch: 3 best f1: 0.78049 best logloss: 0.55060\n",
      "Fold5 Epoch 4/20\n",
      "valf1: 0.7435  valLogLoss: 0.5099\n",
      "Fold5 Epoch 5/20\n",
      "valf1: 0.7870  valLogLoss: 0.4711\n",
      "save best epoch: 5 best f1: 0.78700 best logloss: 0.47109\n",
      "Fold5 Epoch 6/20\n",
      "valf1: 0.8014  valLogLoss: 0.4502\n",
      "save best epoch: 6 best f1: 0.80142 best logloss: 0.45023\n",
      "Fold5 Epoch 7/20\n",
      "valf1: 0.7875  valLogLoss: 0.4353\n",
      "Fold5 Epoch 8/20\n",
      "valf1: 0.7958  valLogLoss: 0.4295\n",
      "Fold5 Epoch 9/20\n",
      "valf1: 0.7817  valLogLoss: 0.4285\n",
      "Fold5 Epoch 10/20\n",
      "valf1: 0.8123  valLogLoss: 0.4171\n",
      "save best epoch: 10 best f1: 0.81229 best logloss: 0.41705\n",
      "Fold5 Epoch 11/20\n",
      "valf1: 0.7960  valLogLoss: 0.4119\n",
      "Fold5 Epoch 12/20\n",
      "valf1: 0.7889  valLogLoss: 0.4110\n",
      "Fold5 Epoch 13/20\n",
      "valf1: 0.7758  valLogLoss: 0.4190\n",
      "Fold5 Epoch 14/20\n",
      "valf1: 0.7889  valLogLoss: 0.4051\n",
      "Fold5 Epoch 15/20\n",
      "valf1: 0.7845  valLogLoss: 0.4114\n",
      "Fold5 Epoch 16/20\n",
      "valf1: 0.7902  valLogLoss: 0.4095\n",
      "Fold5 Epoch 17/20\n",
      "valf1: 0.7930  valLogLoss: 0.4067\n",
      "Fold5 Epoch 18/20\n",
      "valf1: 0.7930  valLogLoss: 0.4083\n",
      "Fold5 Epoch 19/20\n",
      "valf1: 0.7930  valLogLoss: 0.4082\n",
      "Fold5 Epoch 20/20\n",
      "valf1: 0.7930  valLogLoss: 0.4085\n",
      "Fold5 Best f1: 0.812 Best logloss: 0.417 Best epoch:10\n",
      "[0.8193548387096774, 0.8253968253968254, 0.8036809815950919, 0.8403908794788273, 0.8122866894197952]\n",
      "loss... 0.4446576748419998 f1... 0.8202220429200434\n"
     ]
    }
   ],
   "source": [
    "setup_seed(2021)\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "print_interval=-1\n",
    "kfold_best_loss = []\n",
    "kfold_best_f1 = []\n",
    "# print(len(df))\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['tag'].values)):\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        myDataset(df, train_idx), \n",
    "        batch_size=32, shuffle=True, pin_memory=True, num_workers=1)\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        myDataset(df, val_idx), \n",
    "        batch_size=128, shuffle=False, pin_memory=True, num_workers=1)\n",
    "    model = SeqNet()\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4 ,weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epoch)\n",
    "\n",
    "    best_loss, best_acc = train_model(model, criterion, optimizer, lr_scheduler=scheduler)\n",
    "    kfold_best_loss.append(best_loss)\n",
    "    kfold_best_f1.append(best_acc)\n",
    "\n",
    "print(kfold_best_f1)                  \n",
    "print('loss...', np.mean(kfold_best_loss), 'f1...', np.mean(kfold_best_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7LgNPIO3313N"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "def load_model(weight_path):\n",
    "    print(weight_path)\n",
    "    model = SeqNet()\n",
    "    model.load_state_dict(torch.load(weight_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(test_loader):\n",
    "    ret = 0\n",
    "    for i, model in enumerate(model_list):\n",
    "        print('----model ', i)\n",
    "        pres_list = []\n",
    "        for data in tqdm(test_loader):\n",
    "            inputs, _a = data\n",
    "            inputs = inputs.cuda()\n",
    "            outputs = model(inputs)\n",
    "            pres_list+=outputs.sigmoid().detach().cpu().numpy().tolist()\n",
    "        ret += np.array(pres_list) / len(model_list)\n",
    "    return list(map(lambda x: 1 if x > 0.5 else 0, ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xDLSTgf833S_",
    "outputId": "bcf6b121-14f0-41e5-f016-76e36e9ca56d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive/MyDrive/心电图/model/fold_1_best.pth\n",
      "drive/MyDrive/心电图/model/fold_2_best.pth\n",
      "drive/MyDrive/心电图/model/fold_3_best.pth\n",
      "drive/MyDrive/心电图/model/fold_4_best.pth\n",
      "drive/MyDrive/心电图/model/fold_5_best.pth\n",
      "----model  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:22<00:00,  3.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----model  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----model  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----model  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----model  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:03<00:00,  2.27it/s]\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda')\n",
    "model_list=[]\n",
    "for i in range(5):\n",
    "    model_list.append(load_model(path+'model/fold_'+str(i+1)+'_best.pth'))\n",
    "import os\n",
    "\n",
    "sub = pd.read_csv(path+'answer.csv')\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        myDataset(sub, if_train=False), \n",
    "        batch_size=64, shuffle=False, num_workers=16, pin_memory=True)\n",
    "sub['tag'] = predict(test_loader)\n",
    "sub.to_csv(path+'ans/sub_20211118_%.5f.csv'%np.mean(kfold_best_f1), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ov0dvb3ZNPP3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "aiwin心电图",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
